#!/bin/bash
#SBATCH -J consensus_mistral
#SBATCH -A tesr108469
#SBATCH -p gpu_h100           # <— 80 GB GPU. If unavailable, change back to gpu_a100
#SBATCH --gpus=1
#SBATCH --ntasks=1            # <— IMPORTANT: only one task
#SBATCH --cpus-per-task=8
#SBATCH --mem=40G
#SBATCH --time=00:30:00
#SBATCH -o logs/%x-%j.out

set -euo pipefail
cd "$SLURM_SUBMIT_DIR"
mkdir -p logs runs analytics

# Per-job HF cache on node-local scratch
export HF_HOME="${TMPDIR:-/scratch-local/$USER/${SLURM_JOB_ID}}/hf"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export HF_DATASETS_CACHE="$HF_HOME/datasets"
mkdir -p "$HF_HOME"

# Help PyTorch allocate large contiguous blocks
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# Ensure our src/ is importable (template_loader, etc.)
export PYTHONPATH="$SLURM_SUBMIT_DIR/src:${PYTHONPATH:-}"

# Activate env
source ~/.venvs/consensus/bin/activate

# Make sure cuDNN is visible (matches cu121 wheels already installed)
python - <<'PY'
import sys, subprocess
try:
    import nvidia.cudnn as _
    print("cuDNN present")
except Exception:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "--no-cache-dir", "nvidia-cudnn-cu12>=9,<10"])
PY

# Scenario arg
SCENARIO_ID="${1:?usage: sbatch run_gpu_mistral.job <scenario_id>}"

# Run (single task)
srun --ntasks=1 python -m src.main --scenario "$SCENARIO_ID" \
  --model-a mistralai/Mistral-7B-Instruct-v0.3 \
  --model-b mistralai/Mistral-7B-Instruct-v0.3 \
  --dtype bf16
