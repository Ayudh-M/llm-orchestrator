#!/bin/bash
#SBATCH --job-name=llm-dual
#SBATCH --time=00:30:00
#SBATCH --nodes=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=48G
#SBATCH --output=logs/%x.%j.out
#SBATCH --error=logs/%x.%j.err

set -euo pipefail

mkdir -p logs runs

echo "JOB_ID=$SLURM_JOB_ID"
echo "HOST=$(hostname)"
echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
nvidia-smi || true

export HF_HOME=${HF_HOME:-$SCRATCH/hf_cache}
export HF_DATASETS_CACHE=${HF_DATASETS_CACHE:-$SCRATCH/hf_datasets}
export TRANSFORMERS_OFFLINE=0

PROMPT="$1"
ROLESET="$2"
STRATEGY="${3:-strategy-01}"

python -m src.main           --prompt "$PROMPT"           --roleset "$ROLESET"           --strategy "$STRATEGY"           --models "a=mistralai/Mistral-7B-Instruct-v0.2 b=mistralai/Mistral-7B-Instruct-v0.2"           --max_rounds 8
